{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5adb4ed-96d0-49e9-95b9-fdad50a75751",
   "metadata": {},
   "source": [
    "# Grasping with IK and Motion Planning\n",
    "\n",
    "In this section, we’ll walk through a simple grasping task, showing how to use **inverse kinematics (IK)** together with **motion planning** to pick up a cube.\n",
    "\n",
    "### What You Will Learn\n",
    "\n",
    "1. Applying Inverse Kinematics (IK)\n",
    "Use `franka.inverse_kinematics()` to automatically determine the robot’s joint angles for specific poses, such as hovering above or grasping the cube.\n",
    "\n",
    "2. Using Motion Planning for Smooth Trajectories\n",
    "Learn how `plan_path()` interpolates joint-space waypoints between the current and goal poses.\n",
    "\n",
    "3. Performing a Full Grasping Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b774e89-ff67-4285-a5da-f47170945e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warning messages for clearer output\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "os.environ[\"TI_LOG_LEVEL\"] = \"error\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204d0dbb-69c6-42d1-8c57-cec4b082ba27",
   "metadata": {},
   "source": [
    "## Init and Create a Scene\n",
    "\n",
    "Because the iGPU currently requires additional edge-case handling to ensure correct program execution when calling complex IK functions, we use the CPU backend in this lab to keep the code simple and easy to understand. If you are using an AMD dGPU, you can call the IK functions with the Vulkan backend directly, no extra handling is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a9c1c3-7661-40d7-b895-79de1d0337e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;17m[Genesis] [10:30:09] [INFO] \u001b[38;5;23m╭───────────────────────────────────────────────╮\u001b[0m\u001b[38;5;17m\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:09] [INFO] \u001b[38;5;23m│┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈\u001b[0m\u001b[38;5;17m \u001b[38;5;23m\u001b[1m\u001b[3mGenesis\u001b[0m\u001b[38;5;17m \u001b[38;5;23m┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈│\u001b[0m\u001b[38;5;17m\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:09] [INFO] \u001b[38;5;23m╰───────────────────────────────────────────────╯\u001b[0m\u001b[38;5;17m\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:10] [INFO] Consider setting 'performance_mode=True' in production to maximise runtime speed, if significantly increasing compilation time is not a concern.\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:10] [INFO] Running on \u001b[38;5;23m\u001b[4m[AMD RYZEN AI MAX+ 395 w/ Radeon 8060S]\u001b[0m\u001b[38;5;17m with backend \u001b[38;5;23m\u001b[4mgs.cpu\u001b[0m\u001b[38;5;17m. Device memory: \u001b[38;5;23m\u001b[4m121.50\u001b[0m\u001b[38;5;17m GB.\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:10] [INFO] 🚀 Genesis initialized. 🔖 version: \u001b[38;5;23m\u001b[4m0.3.3\u001b[0m\u001b[38;5;17m, 🌱 seed: \u001b[38;5;23m\u001b[4mNone\u001b[0m\u001b[38;5;17m, 📏 precision: '\u001b[38;5;23m\u001b[4m32\u001b[0m\u001b[38;5;17m', 🐛 debug: \u001b[38;5;23m\u001b[4mFalse\u001b[0m\u001b[38;5;17m, 🎨 theme: '\u001b[38;5;23m\u001b[4mlight\u001b[0m\u001b[38;5;17m'.\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:10] [INFO] Scene \u001b[38;5;23m\u001b[3m<b32bbaa>\u001b[0m\u001b[38;5;17m created.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import genesis as gs\n",
    "import numpy as np\n",
    "\n",
    "########################## init ##########################\n",
    "gs.init(backend=gs.cpu, theme='light')\n",
    "\n",
    "########################## create a scene ##########################\n",
    "scene = gs.Scene(\n",
    "    viewer_options=gs.options.ViewerOptions(\n",
    "        camera_pos=(3, -1, 1.5),\n",
    "        camera_lookat=(0.0, 0.0, 0.5),\n",
    "        camera_fov=30,\n",
    "        max_FPS=60,\n",
    "    ),\n",
    "    sim_options=gs.options.SimOptions(\n",
    "        dt=0.01,\n",
    "    ),\n",
    "    show_viewer=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9816b-1905-47ff-acb1-1b65e78cb62e",
   "metadata": {},
   "source": [
    "## Add Entities and Build the Scene\n",
    "\n",
    "Just like what we did in Lab 1, we add a plane, an arm, and a camera to the scene, and then build the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85fca6cf-23ec-4925-b691-8208ae7489af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;17m[Genesis] [10:30:15] [INFO] Adding \u001b[38;5;23m<gs.RigidEntity>\u001b[0m\u001b[38;5;17m. idx: \u001b[38;5;23m0\u001b[0m\u001b[38;5;17m, uid: \u001b[38;5;23m\u001b[3m<f5dceb5>\u001b[0m\u001b[38;5;17m, morph: \u001b[38;5;23m<gs.morphs.Plane>\u001b[0m\u001b[38;5;17m, material: \u001b[38;5;23m<gs.materials.Rigid>\u001b[0m\u001b[38;5;17m.\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:15] [INFO] Adding \u001b[38;5;23m<gs.RigidEntity>\u001b[0m\u001b[38;5;17m. idx: \u001b[38;5;23m1\u001b[0m\u001b[38;5;17m, uid: \u001b[38;5;23m\u001b[3m<f4ee1ca>\u001b[0m\u001b[38;5;17m, morph: \u001b[38;5;23m<gs.morphs.Box>\u001b[0m\u001b[38;5;17m, material: \u001b[38;5;23m<gs.materials.Rigid>\u001b[0m\u001b[38;5;17m.\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:15] [INFO] Adding \u001b[38;5;23m<gs.RigidEntity>\u001b[0m\u001b[38;5;17m. idx: \u001b[38;5;23m2\u001b[0m\u001b[38;5;17m, uid: \u001b[38;5;23m\u001b[3m<1728596>\u001b[0m\u001b[38;5;17m, morph: \u001b[38;5;23m<gs.morphs.MJCF(file='/opt/conda/envs/py_3.12/lib/python3.12/site-packages/genesis/assets/xml/franka_emika_panda/panda.xml')>\u001b[0m\u001b[38;5;17m, material: \u001b[38;5;23m<gs.materials.Rigid>\u001b[0m\u001b[38;5;17m.\u001b[0m\n",
      "\u001b[38;5;3m[Genesis] [10:30:16] [WARNING] (MJCF) Approximating tendon by joint actuator for `finger_joint1`\u001b[0m\n",
      "\u001b[38;5;3m[Genesis] [10:30:16] [WARNING] (MJCF) Actuator control gain and bias parameters cannot be reduced to a unique PD control position gain. Using max between gain and bias for joint `finger_joint1`.\u001b[0m\n",
      "\u001b[38;5;3m[Genesis] [10:30:16] [WARNING] (MJCF) Approximating tendon by joint actuator for `finger_joint2`\u001b[0m\n",
      "\u001b[38;5;3m[Genesis] [10:30:16] [WARNING] (MJCF) Actuator control gain and bias parameters cannot be reduced to a unique PD control position gain. Using max between gain and bias for joint `finger_joint2`.\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:16] [INFO] Applying offset to base link's pose with user provided value in morph.\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:16] [INFO] Building scene \u001b[38;5;23m\u001b[3m<b32bbaa>\u001b[0m\u001b[38;5;17m...\u001b[0m\n",
      "\u001b[38;5;3m[Genesis] [10:30:17] [WARNING] Reference robot position exceeds joint limits.\u001b[0m\n",
      "\u001b[38;5;3m[Genesis] [10:30:17] [WARNING] Constraint solver time constant should be greater than 2*substep_dt. timeconst is changed from `0.005` to `0.02`). Decrease simulation timestep or increase timeconst to avoid altering the original value.\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:18] [INFO] Compiling simulation kernels...\u001b[0m\n",
      "\u001b[38;5;17m[Genesis] [10:30:22] [INFO] Building visualizer...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "amdgpu: os_same_file_description couldn't determine if two DRM fds reference the same file description.\n",
      "If they do, bad things may happen!\n"
     ]
    }
   ],
   "source": [
    "########################## entities ##########################\n",
    "plane = scene.add_entity(\n",
    "    gs.morphs.Plane(),\n",
    ")\n",
    "cube = scene.add_entity(\n",
    "    gs.morphs.Box(\n",
    "        size=(0.04, 0.04, 0.04),\n",
    "        pos=(0.65, 0.0, 0.02),\n",
    "    )\n",
    ")\n",
    "franka = scene.add_entity(\n",
    "    gs.morphs.MJCF(file=\"xml/franka_emika_panda/panda.xml\"),\n",
    ")\n",
    "cam = scene.add_camera(\n",
    "    res=(640, 480),\n",
    "    pos=(3, -1, 1.5),\n",
    "    lookat=(0, 0, 0.5),\n",
    "    fov=30,\n",
    "    GUI=True,\n",
    ")\n",
    "########################## build ##########################\n",
    "scene.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae79515-10b9-4853-bafc-ade2a851640f",
   "metadata": {},
   "source": [
    "## Set Control Gains\n",
    "\n",
    "Just like Lab2, we set control gains for the arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac12a53-5b5b-4533-b1e8-a5b901444dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb, depth, segmentation, normal = cam.render(rgb=True, depth=True, segmentation=True, normal=True)\n",
    "cam.start_recording()\n",
    "\n",
    "motors_dof = np.arange(7)\n",
    "fingers_dof = np.arange(7, 9)\n",
    "\n",
    "# set control gains\n",
    "franka.set_dofs_kp(\n",
    "    np.array([4500, 4500, 3500, 3500, 2000, 2000, 2000, 100, 100]),\n",
    ")\n",
    "franka.set_dofs_kv(\n",
    "    np.array([450, 450, 350, 350, 200, 200, 200, 10, 10]),\n",
    ")\n",
    "franka.set_dofs_force_range(\n",
    "    np.array([-87, -87, -87, -87, -12, -12, -12, -100, -100]),\n",
    "    np.array([87, 87, 87, 87, 12, 12, 12, 100, 100]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c9877a-3fcb-4782-910a-55414d83778d",
   "metadata": {},
   "source": [
    "## Inverse Kinematics (IK)\n",
    "\n",
    "Inverse Kinematics lets us compute the robot’s joint positions for a given end-effector pose (position + orientation). This is essential for telling the robot where the hand should go, without manually specifying every joint angle.\n",
    "\n",
    "Let’s go step by step through the grasping process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c70acb-449f-4446-9f31-8b04e69ce8b0",
   "metadata": {},
   "source": [
    "### 1. Define the End-Effector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361bd79d-3710-4fb8-9c82-967c536d7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_effector = franka.get_link(\"hand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6218a59-73be-4ad0-a75b-e498973e4215",
   "metadata": {},
   "source": [
    "### 2. Move to a Pre-Grasp Pose\n",
    "\n",
    "We’ll solve IK for a position directly above the cube, and open the gripper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bedf4dfe-d51c-484b-baaf-b351bc1c8406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to pre-grasp pose\n",
    "qpos = franka.inverse_kinematics(\n",
    "    link=end_effector,\n",
    "    pos=np.array([0.65, 0.0, 0.25]),\n",
    "    quat=np.array([0, 1, 0, 0]),\n",
    ")\n",
    "# gripper open pos\n",
    "qpos[-2:] = 0.04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b99f1-1209-47dc-aa6d-9212037d0f5c",
   "metadata": {},
   "source": [
    "To reach this smoothly, we use the motion planner. `plan_path` interpolates between the current joint angles and the target, generating a sequence of waypoints. Executing them one by one produces a natural trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ef0fd2-1b2e-408c-adb3-d16862a09112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing motion path: 100%|██████████████████████████████████████| 200/200 [00:04<00:00, 46.81it/s]\n",
      "Reach the last waypoint: 100%|████████████████████████████████████| 100/100 [00:02<00:00, 48.27it/s]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set logger to warning to avoid log info.\n",
    "gs.logger._logger.setLevel(logging.WARNING)\n",
    "\n",
    "path = franka.plan_path(\n",
    "    qpos_goal=qpos,\n",
    "    num_waypoints=200,  # 2s duration\n",
    ")\n",
    "# draw the planned path\n",
    "path_debug = scene.draw_debug_path(path, franka)\n",
    "\n",
    "# execute the planned path\n",
    "for waypoint in tqdm(path, desc=\"Executing motion path\", ncols=100):\n",
    "    franka.control_dofs_position(waypoint)\n",
    "    cam.render()\n",
    "    scene.step()\n",
    "\n",
    "# remove the drawn path\n",
    "scene.clear_debug_object(path_debug)\n",
    "\n",
    "# allow robot to reach the last waypoint\n",
    "for i in tqdm(range(100), desc=\"Reach the last waypoint\", ncols=100):\n",
    "    cam.render()\n",
    "    scene.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c71e74-0e0d-4505-9009-1410d3099666",
   "metadata": {},
   "source": [
    "### 3. Lower the Gripper\n",
    "\n",
    "Now we solve IK again, this time just above the cube’s top surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c9b2e21-6f85-4220-8d59-d05990823ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lower the gripper: 100%|██████████████████████████████████████████| 100/100 [00:02<00:00, 48.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# reach\n",
    "qpos = franka.inverse_kinematics(\n",
    "    link=end_effector,\n",
    "    pos=np.array([0.65, 0.0, 0.130]),\n",
    "    quat=np.array([0, 1, 0, 0]),\n",
    ")\n",
    "\n",
    "franka.control_dofs_position(qpos[:-2], motors_dof)\n",
    "for i in tqdm(range(100), desc=\"Lower the gripper\", ncols=100):\n",
    "    cam.render()\n",
    "    scene.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003333e-6bdd-462e-ab01-a2a695f13976",
   "metadata": {},
   "source": [
    "### 4. Close the Fingers (Grasp)\n",
    "\n",
    "We command the arm to hold its joint position, then apply closing force to the gripper fingers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "583befbf-0a92-4540-840a-64204dbeedc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Close the finger: 100%|███████████████████████████████████████████| 100/100 [00:02<00:00, 48.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# grasp\n",
    "franka.control_dofs_position(qpos[:-2], motors_dof)\n",
    "franka.control_dofs_force(np.array([-0.5, -0.5]), fingers_dof)\n",
    "\n",
    "for i in tqdm(range(100), desc=\"Close the finger\", ncols=100):\n",
    "    cam.render()\n",
    "    scene.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fcd0f-c35a-4d42-8ef1-7f9688ead63a",
   "metadata": {},
   "source": [
    "### 5. Lift the Cube\n",
    "\n",
    "Finally, we solve IK for a higher position and move the arm upwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45581280-45c5-44a7-afcb-33cbf44a8ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lift the cude: 100%|██████████████████████████████████████████████| 100/100 [00:02<00:00, 48.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# lift\n",
    "qpos = franka.inverse_kinematics(\n",
    "    link=end_effector,\n",
    "    pos=np.array([0.65, 0.0, 0.28]),\n",
    "    quat=np.array([0, 1, 0, 0]),\n",
    ")\n",
    "\n",
    "franka.control_dofs_position(qpos[:-2], motors_dof)\n",
    "for i in tqdm(range(100), desc=\"Lift the cude\", ncols=100):\n",
    "    cam.render()\n",
    "    scene.step()\n",
    "\n",
    "cam.stop_recording(save_to_filename=\"Videos/video_03.mp4\", fps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bbc69c-4d27-42b7-a3d7-28b3e25b22e9",
   "metadata": {},
   "source": [
    "## Show the video\n",
    "\n",
    "In the video, you will see the robotic arm plan a path to pick up the block. It opens its gripper and then moves downward to grasp the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eda4709b-4663-41ac-850e-6be12eb52311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"Videos/video_03.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(url=\"Videos/video_03.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08073f-1121-4d36-8ba4-0f13c1cf1853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
